{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Regular Expressions (Google Edition)\n",
    "\n",
    "1. Basic Patterns\n",
    "2. Basic Examples\n",
    "3. Repetition\n",
    "    - Leftmost & Largest\n",
    "4. Repetition Examples\n",
    "5. Emails Example\n",
    "    - Square Brackets\n",
    "6. Group Extraction\n",
    "7. findall()\n",
    "8. findall() with Files\n",
    "9. findall() and Groups\n",
    "10. RE Workflow and Debug\n",
    "11. Options\n",
    "12. Greedy vs. Non-Greedy (Optional)\n",
    "13. Substitution (optional)\n",
    "14. Exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found word:cat\n"
     ]
    }
   ],
   "source": [
    "string = 'an example word:cat!!'\n",
    "match = re.search(r'word:\\w\\w\\w', string)\n",
    "# If-statement after search() tests if it succeeded\n",
    "if match:\n",
    "    # 'Found word:cat')\n",
    "    print('Found', match.group())\n",
    "else:\n",
    "    print('Did not find')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Patterns\n",
    "\n",
    "The power of regular expressions is that they can specify patterns, not just fixed characters. Here are the most basic patterns which match single chars:\n",
    "\n",
    "- a, X, 9, < -- ordinary characters just match themselves exactly. The meta-characters which do not match themselves because they have special meanings are: . ^ $ * + ? { [ ] \\ | ( ) (details below)\n",
    "\n",
    "- . (a period) -- matches any single character except newline '\\n'\n",
    "\n",
    "- \\w -- (lowercase w) matches a \"word\" character: a letter or digit or underbar [a-zA-Z0-9_]. Note that although \"word\" is the mnemonic for this, it only matches a single word char, not a whole word. \\W (upper case W) matches any non-word character.\n",
    "\n",
    "- \\b -- boundary between word and non-word\n",
    "\n",
    "- \\s -- (lowercase s) matches a single whitespace character -- space, newline, return, tab, form [ \\n\\r\\t\\f]. \\S (upper case S) matches any non-whitespace character.\n",
    "\n",
    "- \\t, \\n, \\r -- tab, newline, return\n",
    "\n",
    "- \\d -- decimal digit [0-9] (some older regex utilities do not support but \\d, but they all support \\w and \\s)\n",
    "\n",
    "- ^ = start, $ = end -- match the start or end of the string\n",
    "\n",
    "- \\ -- inhibit the \"specialness\" of a character. So, for example, use \\. to match a period or \\\\ to match a slash. If you are unsure if a character has special meaning, such as '@', you can put a slash in front of it, \\@, to make sure it is treated just as a character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Examples\n",
    "Joke: what do you call a pig with three eyes? piiig!\n",
    "\n",
    "The basic rules of regular expression search for a pattern within a string are:\n",
    "\n",
    "- The search proceeds through the string from start to end, stopping at the first match found\n",
    "- All of the pattern must be matched, but not all of the string\n",
    "- If match = re.search(pat, str) is successful, match is not None and in particular match.group() is the matching text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iii\n",
      "iig\n",
      "123\n",
      "abc\n"
     ]
    }
   ],
   "source": [
    "## Search for pattern 'iii' in string 'piiig'.\n",
    "## All of the pattern must match, but it may appear anywhere.\n",
    "## On success, match.group() is matched text.\n",
    "match = re.search(r'iii', 'piiig') # found, match.group() == \"iii\"\n",
    "print(match.group())\n",
    "match = re.search(r'igs', 'piiig') # not found, match == None\n",
    "# print(match.group())\n",
    "\n",
    "## . = any char but \\n\n",
    "match = re.search(r'..g', 'piiig') # found, match.group() == \"iig\"\n",
    "print(match.group())\n",
    "\n",
    "## \\d = digit char, \\w = word char\n",
    "match = re.search(r'\\d\\d\\d', 'p123g') # found, match.group() == \"123\"\n",
    "print(match.group())\n",
    "\n",
    "match = re.search(r'\\w\\w\\w', '@@abcd!!') # found, match.group() == \"abc\"\n",
    "print(match.group())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repetition\n",
    "Things get more interesting when you use + and * to specify repetition in the pattern\n",
    "\n",
    "- + -- 1 or more occurrences of the pattern to its left, e.g. 'i+' = one or more i's\n",
    "- * -- 0 or more occurrences of the pattern to its left\n",
    "- ? -- match 0 or 1 occurrences of the pattern to its left\n",
    "\n",
    "#### Leftmost & Largest\n",
    "First the search finds the leftmost match for the pattern, and second it tries to use up as much of the string as possible -- i.e. + and * go as far as possible (the + and * are said to be \"greedy\").\n",
    "\n",
    "### Repetition Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piii\n",
      "ii\n"
     ]
    }
   ],
   "source": [
    "# i+ = one or more i's, as many as possible.\n",
    "match = re.search(r'pi+', 'piiig')\n",
    "print(match.group())\n",
    "\n",
    "# Match the first fulfilled term\n",
    "# In this example, note that it does not get to the second set of i's.\n",
    "match = re.search(r'i+', 'piigiiii')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2   3\n",
      "12  3\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "# \\s* = zero or more whitespace chars\n",
    "# Here look for 3 digits, possibly separated by whitespace.\n",
    "match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx1 2   3xx') # found, match.group() == \"1 2   3\"\n",
    "print(match.group())\n",
    "match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx12  3xx') # found, match.group() == \"12  3\"\n",
    "print(match.group())\n",
    "match = re.search(r'\\d\\s*\\d\\s*\\d', 'xx123xx') # found, match.group() == \"123\"\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n"
     ]
    }
   ],
   "source": [
    "# ^ = matches the start of string, so this fails:\n",
    "match = re.search(r'^b\\w+', 'foobar') # not found, match == None\n",
    "# print(match.group())\n",
    "\n",
    "# but without the ^ it succeeds:\n",
    "match = re.search(r'b\\w+', 'foobar') # found, match.group() == \"bar\"\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails Example\n",
    "Suppose you want to find the email address inside the string 'xyz alice-b@google.com purple monkey'. We'll use this as a running example to demonstrate more regular expression features. \n",
    "\n",
    "Here's an attempt using the pattern __r'\\w+@\\w+'__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b@google\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice-b@google.com monkey dishwasher'\n",
    "match = re.search(r'\\w+@\\w+', str)\n",
    "if match:\n",
    "    print(match.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square Brackets\n",
    "Square brackets can be used to indicate a set of chars, so [abc] matches 'a' or 'b' or 'c'. The codes \\w, \\s etc. work inside square brackets too with the one exception that dot (.) just means a literal dot. For the emails problem, the square brackets are an easy way to add '.' and '-' to the set of chars which can appear around the @ with the pattern r'[\\w.-]+@[\\w.-]+' to get the whole email address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-b@google.com\n"
     ]
    }
   ],
   "source": [
    "match = re.search(r'[\\w.-]+@[\\w.-]+', str)\n",
    "if match:\n",
    "    print(match.group())  ## 'alice-b@google.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(More square-bracket features) You can also use a dash to indicate a range, so [a-z] matches all lowercase letters. \n",
    "\n",
    "To use a dash without indicating a range, put the dash last, e.g. [abc-]. \n",
    "\n",
    "An up-hat (^) at the start of a square-bracket set inverts it, so [^ab] means any char except 'a' or 'b'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Extraction\n",
    "\n",
    "The \"group\" feature of a regular expression allows you to pick out parts of the matching text. Suppose for the emails problem that we want to extract the username and host separately. To do this, add parenthesis ( ) around the username and host in the pattern, like this: r'([\\w.-]+)@([\\w.-]+)'. In this case, the parenthesis do not change what the pattern will match, instead they establish logical \"groups\" inside of the match text. On a successful search, match.group(1) is the match text corresponding to the 1st left parenthesis, and match.group(2) is the text corresponding to the 2nd left parenthesis. The plain match.group() is still the whole match text as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-b@google.com\n",
      "alice-b\n",
      "google.com\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice-b@google.com monkey dishwasher'\n",
    "match = re.search(r'([\\w.-]+)@([\\w.-]+)', str)\n",
    "if match:\n",
    "    print(match.group())   ## 'alice-b@google.com' (the whole match)\n",
    "    print(match.group(1))  ## 'alice-b' (the username, group 1)\n",
    "    print(match.group(2))  ## 'google.com' (the host, group 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common workflow with regular expressions is that you write a pattern for the thing you are looking for, adding parenthesis groups to extract the parts you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall\n",
    "__findall()__ is probably the single most powerful function in the re module. Above we used re.search() to find the first match for a pattern. \n",
    "\n",
    "__findall()__ finds *all* the matches and returns them as a list of strings, with each string representing one match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@google.com\n",
      "bob@abc.com\n"
     ]
    }
   ],
   "source": [
    "## Suppose we have a text with many email addresses\n",
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "\n",
    "## Here re.findall() returns a list of all the found email strings\n",
    "emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', str) ## ['alice@google.com', 'bob@abc.com']\n",
    "for email in emails:\n",
    "    # do something with each found email string\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall() With Files\n",
    "For files, you may be in the habit of writing a loop to iterate over the lines of the file, and you could then call __findall()__ on each line. \n",
    "\n",
    "Instead, let __findall()__ do the iteration for you -- much better! \n",
    "\n",
    "Just feed the whole file text into __findall()__ and let it return a list of all the matches in a single step (recall that f.read() returns the whole text of a file in a single string):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a list: \n",
      "['alice@google.com', 'bob@abc.com']\n",
      "\n",
      "String in list 1 by 1:\n",
      "alice@google.com\n",
      "bob@abc.com\n"
     ]
    }
   ],
   "source": [
    "# Open file\n",
    "f = open('test.txt', 'r')\n",
    "\n",
    "# Feed the file text into findall(); it returns a list of all the found strings\n",
    "strings = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', f.read())\n",
    "print(f'In a list: \\n{strings}\\n')\n",
    "\n",
    "print('String in list 1 by 1:')\n",
    "for i in strings:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall and Groups\n",
    "The parenthesis ( ) group mechanism can be combined with __findall()__.\n",
    "\n",
    "If the pattern includes 2 or more parenthesis groups, then instead of returning a list of strings, __findall()__ returns a list of *tuples*. Each tuple represents one match of the pattern, and inside the tuple is the group(1), group(2) .. data. \n",
    "\n",
    "So if 2 parenthesis groups are added to the email pattern, then __findall()__ returns a list of tuples, each length 2 containing the username and host, e.g. ('alice', 'google.com')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alice', 'google.com'), ('bob', 'abc.com')]\n",
      "alice\n",
      "google.com\n",
      "bob\n",
      "abc.com\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n",
    "print (tuples)  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n",
    "\n",
    "for tuple in tuples:\n",
    "    print(tuple[0])  ## username\n",
    "    print(tuple[1])  ## host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the list of tuples, you can loop over it to do some computation for each tuple. If the pattern includes no parenthesis, then __findall()__ returns a list of found strings as in earlier examples. If the pattern includes a single set of parenthesis, then __findall()__ returns a list of strings corresponding to that single group. (Obscure optional feature: Sometimes you have paren ( ) groupings in the pattern, but which you do not want to extract. In that case, write the parens with a ?: at the start, e.g. (?: ) and that left paren will not count as a group result.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RE Workflow and Debug\n",
    "\n",
    "Regular expression patterns pack a lot of meaning into just a few characters, but they are so dense, you can spend a lot of time debugging your patterns. \n",
    "\n",
    "Set up your runtime so you can run a pattern and print what it matches easily, for example by running it on a small test text and printing the result of __findall()__. \n",
    "\n",
    "If the pattern matches nothing, try weakening the pattern, removing parts of it so you get too many matches. \n",
    "\n",
    "When it's matching nothing, you can't make any progress since there's nothing concrete to look at. \n",
    "\n",
    "Once it's matching too much, then you can work on tightening it up incrementally to hit just what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options\n",
    "The re functions take options to modify the behavior of the pattern match.\n",
    "\n",
    "The option flag is added as an extra argument to the __search()__ or __findall()__ etc., \n",
    "\n",
    "_e.g. re.search(pat, str, re.IGNORECASE)_.\n",
    "\n",
    "- __IGNORECASE__ -- ignore upper/lowercase differences for matching, so 'a' matches both 'a' and 'A'.\n",
    "- __DOTALL__ -- allow dot (.) to match newline -- normally it matches anything but newline. This can trip you up -- you think .* matches everything, but by default it does not go past the end of a line. Note that \\s (whitespace) includes newlines, so if you want to match a run of whitespace that may include a newline, you can just use \\s*\n",
    "- __MULTILINE__ -- Within a string made of many lines, allow ^ and $ to match the start and end of each line. Normally ^/$ would just match the start and end of the whole string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy vs. Non-Greedy (optional)\n",
    "This is optional section which shows a more advanced regular expression technique not needed for the exercises.\n",
    "\n",
    "Suppose you have text with tags in it: <b>foo</b> and <i>so on</i>\n",
    "\n",
    "Suppose you are trying to match each tag with the pattern '(<.*>)' -- what does it match first?\n",
    "\n",
    "The result is a little surprising, but the greedy aspect of the .* causes it to match the whole '<b>foo</b> and <i>so on</i>' as one big match. The problem is that the .* goes as far as is it can, instead of stopping at the first > (aka it is \"greedy\").\n",
    "\n",
    "There is an extension to regular expression where you add a ? at the end, such as .*? or .+?, changing them to be non-greedy. Now they stop as soon as they can. So the pattern '(<.*?>)' will get just '<b>' as the first match, and '</b>' as the second match, and so on getting each <..> pair in turn. The style is typically that you use a .*?, and then immediately its right look for some concrete marker (> in this case) that forces the end of the .*? run.\n",
    "\n",
    "The *? extension originated in Perl, and regular expressions that include Perl's extensions are known as Perl Compatible Regular Expressions -- pcre. Python includes pcre support. Many command line utils etc. have a flag where they accept pcre patterns.\n",
    "\n",
    "An older but widely used technique to code this idea of \"all of these chars except stopping at X\" uses the square-bracket style. For the above you could write the pattern, but instead of .* to get all the chars, use [^>]* which skips over all characters which are not > (the leading ^ \"inverts\" the square bracket set, so it matches any char not in the brackets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution (optional)\n",
    "The __re.sub(pat, replacement, str)__ function searches for all the instances of pattern in the given string, and replaces them. The replacement string can include '\\1', '\\2' which refer to the text from group(1), group(2), and so on from the original matching text.\n",
    "\n",
    "Here's an example which searches for all the email addresses, and changes them to keep the user (\\1) but have yo-yo-dyne.com as the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple alice@yo-yo-dyne.com, blah monkey bob@yo-yo-dyne.com blah dishwasher\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "\n",
    "## re.sub(pat, replacement, str) -- returns new string with all replacements,\n",
    "## \\1 is group(1), \\2 group(2) in the replacement\n",
    "print(re.sub(r'([\\w\\.-]+)@([\\w\\.-]+)', r'\\1@yo-yo-dyne.com', str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
